{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7a0ca2",
   "metadata": {},
   "source": [
    "# ASR Example - Unified Transcription Interface\n",
    "\n",
    "Audio Speech Recognition with aisuite's unified API supporting OpenAI, Deepgram, and Google providers.\n",
    "\n",
    "This example demonstrates:\n",
    "- Basic transcription with kwargs (OpenAI format)\n",
    "- Advanced transcription with TranscriptionOptions\n",
    "- Provider-specific features using custom_parameters\n",
    "- Streaming transcription support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72f8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "from aisuite.framework.message import TranscriptionOptions, TranscriptionResult\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "# Set up client with provider configurations\n",
    "client = ai.Client({\n",
    "    \"openai\": {\"api_key\": os.getenv(\"OPENAI_API_KEY\")},\n",
    "    \"deepgram\": {\"api_key\": os.getenv(\"DEEPGRAM_API_KEY\")},\n",
    "    \"google\": {\n",
    "        \"project_id\": os.getenv(\"GOOGLE_PROJECT_ID\"),\n",
    "        \"region\": os.getenv(\"GOOGLE_REGION\"),\n",
    "        \"application_credentials\": os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"),\n",
    "    },\n",
    "})\n",
    "\n",
    "audio_file = \"../aiplayground/speech.mp3\"  # Replace with your audio file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed7f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Transcription ===\n",
      "OpenAI: Good afternoon everyone! Today, I want to take a few minutes to reflect on the importance of making intentional financial decisions early in life, especially when it comes to retirement planning. Many people underestimate the power of compounding, and the difference between starting at age 30 versus starting at 40. By contributing consistently to a retirement account, whether it's a traditional 401k, a Roth 401k, or an IRA, you allow your money to grow, and multiply over decades. The choice between a traditional, and a Roth plan isn't just about preference, it's about strategy. A traditional account lets you save on taxes now, potentially giving you more to invest today. A Roth, on the other hand, asks you to pay taxes up front so your future withdrawals are entirely tax-free. Both have their place, and the right choice depends on your current tax rate, your expected tax rate in retirement, and your long-term financial goals. If you expect your income, and tax rate to be higher in the future, leaning toward Roth contributions might make sense. If your current tax rate is significantly higher than what you expect later, a traditional plan could give you more value. However, the most important thing is not to delay. Timing the market consistently outperforms attempts to perfectly time the market. Start now, automate your contributions, and revisit your plan regularly. Financial freedom isn't built overnight, it's built through small, smart choices made over many years. Thank you.\n",
      "--------------------------------\n",
      "Deepgram: Good afternoon, everyone. Today, I want to take a few minutes to reflect on the importance of making intentional financial decisions early in life, especially when it comes to retirement planning. Many people underestimate the power of compounding and the difference between starting at age 30 versus starting at 40. Are contributing consistently to a retirement account, whether it's a traditional 401 k, a Roth 401 k, or an IRA. You allow your money to grow and multiply over decades. The choice between a traditional and a Roth plan isn't just about preference. It's about strategy. A traditional account lets you pay on taxes now, potentially giving you more to invest today. A Roth, on the other hand, asks you to pay taxes upfront so your future withdrawals are entirely tax free. Both have their place, and the right choice depends on your current tax rate, your expected tax rate in retirement, and your long term financial goals. If you expect your income and tax rate to be higher in the future, leading toward contributions might make sense. If your current tax rate is significantly higher than what you expect later, a traditional plan could give you more value. However, the most important thing is not to delay. Time in the market consistently outperforms attempts to perfectly time the market. Start now. Automate your contributions and revisit your plan regularly. Financial freedom isn't built overnight. It's built through small, smart choices made over many years. Thank you.\n"
     ]
    }
   ],
   "source": [
    "# Basic transcription using kwargs (OpenAI format)\n",
    "print(\"=== Basic Transcription ===\")\n",
    "\n",
    "try:\n",
    "    result = client.audio.transcriptions.create(\n",
    "        model=\"openai:whisper-1\",\n",
    "        file=audio_file,\n",
    "        language=\"en\"\n",
    "    )\n",
    "    if isinstance(result, TranscriptionResult):\n",
    "        print(f\"OpenAI: {result.text}\")\n",
    "    else:\n",
    "        print(\"OpenAI: Got streaming result (not expected for basic call)\")\n",
    "except Exception as e:\n",
    "    print(f\"OpenAI error: {e}\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "try:\n",
    "    # Same kwargs work with other providers (auto-mapped)\n",
    "    result = client.audio.transcriptions.create(\n",
    "        model=\"deepgram:nova-2\",\n",
    "        file=audio_file,\n",
    "        language=\"en\",\n",
    "        punctuate=True\n",
    "    )\n",
    "    if isinstance(result, TranscriptionResult):\n",
    "        print(f\"Deepgram: {result.text}\")\n",
    "    else:\n",
    "        print(\"Deepgram: Got streaming result (not expected for basic call)\")\n",
    "except Exception as e:\n",
    "    print(f\"Deepgram error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3a3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TranscriptionOptions - Unified Interface ===\n",
      "\n",
      "openai:whisper-1:\n",
      "  Text: Good afternoon everyone! Today, I want to take a few minutes to reflect on the importance of making ...\n",
      "  Language: english\n",
      "  Confidence: None\n",
      "\n",
      "deepgram:nova-2:\n",
      "  Text: Good afternoon, everyone. Today, I want to take a few minutes to reflect on the importance of making...\n",
      "  Language: None\n",
      "  Confidence: 0.99798644\n",
      "  Words: 247\n",
      "\n",
      "google:latest_long:\n",
      "  Text: Good afternoon everyone. Today, I want to take a few minutes to reflect on the importance of making ...\n",
      "  Language: None\n",
      "  Confidence: 0.4342968165874481\n",
      "  Words: 197\n"
     ]
    }
   ],
   "source": [
    "# Using TranscriptionOptions for unified interface\n",
    "print(\"\\n=== TranscriptionOptions - Unified Interface ===\")\n",
    "\n",
    "# Create unified options that work across all providers\n",
    "options = TranscriptionOptions(\n",
    "    language=\"en\",\n",
    "    include_word_timestamps=True,\n",
    "    enable_automatic_punctuation=True,\n",
    "    enable_speaker_diarization=True,\n",
    "    max_speakers=3\n",
    ")\n",
    "\n",
    "# Same options work with any provider\n",
    "providers = [\"openai:whisper-1\", \"deepgram:nova-2\", \"google:latest_long\"]\n",
    "\n",
    "for model in providers:\n",
    "    try:\n",
    "        result = client.audio.transcriptions.create(\n",
    "            model=model,\n",
    "            file=audio_file,\n",
    "            options=options\n",
    "        )\n",
    "        if isinstance(result, TranscriptionResult):\n",
    "            print(f\"\\n{model}:\")\n",
    "            print(f\"  Text: {result.text[:100]}...\")\n",
    "            print(f\"  Language: {result.language}\")\n",
    "            print(f\"  Confidence: {result.confidence}\")\n",
    "            if result.words:\n",
    "                print(f\"  Words: {len(result.words)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{model} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provider-specific features using custom_parameters\n",
    "print(\"\\n=== Custom Parameters - Provider-Specific Only ===\")\n",
    "\n",
    "# Single options object with provider-specific parameters\n",
    "# Users MUST namespace parameters by provider\n",
    "advanced_options = TranscriptionOptions(\n",
    "    language=\"en\",\n",
    "    enable_automatic_punctuation=True,\n",
    "    custom_parameters={\n",
    "        # OpenAI-specific parameters (only applied when using OpenAI)\n",
    "        \"openai\": {\n",
    "            \"response_format\": \"verbose_json\",\n",
    "            \"timestamp_granularities\": [\"word\", \"segment\"],\n",
    "            \"temperature\": 0.2\n",
    "        },\n",
    "        # Deepgram-specific parameters (only applied when using Deepgram)\n",
    "        \"deepgram\": {\n",
    "            \"search\": [\"important\", \"keyword\", \"technical\"],\n",
    "            \"replace\": {\"um\": \"\", \"uh\": \"\", \"like\": \"\"},\n",
    "            \"numerals\": True,\n",
    "            \"measurements\": True\n",
    "        },\n",
    "        # Google-specific parameters (only applied when using Google)\n",
    "        \"google\": {\n",
    "            \"use_enhanced\": True,\n",
    "            \"adaptation\": {\"phrase_sets\": [\"technical_terms\"]},\n",
    "            \"metadata\": {\"interaction_type\": \"DISCUSSION\"}\n",
    "        }\n",
    "        # Note: Parameters NOT under a provider key will be IGNORED\n",
    "    }\n",
    ")\n",
    "\n",
    "# Same options work with all providers - only relevant params are used\n",
    "for model in providers:\n",
    "    try:\n",
    "        result = client.audio.transcriptions.create(\n",
    "            model=model,\n",
    "            file=audio_file,\n",
    "            options=advanced_options\n",
    "        )\n",
    "        if isinstance(result, TranscriptionResult):\n",
    "            print(f\"\\n{model} with custom params:\")\n",
    "            print(f\"  Text: {result.text[:80]}...\")\n",
    "            if result.segments:\n",
    "                print(f\"  Segments: {len(result.segments)}\")\n",
    "            if result.alternatives:\n",
    "                print(f\"  Alternatives: {len(result.alternatives)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{model} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming transcription example\n",
    "print(\"\\n=== Streaming Transcription ===\")\n",
    "\n",
    "async def streaming_example():\n",
    "    # Streaming options\n",
    "    streaming_options = TranscriptionOptions(\n",
    "        language=\"en\",\n",
    "        stream=True,  # Enable streaming in options (takes precedence)\n",
    "        interim_results=True,\n",
    "        enable_automatic_punctuation=True,\n",
    "        include_word_timestamps=True\n",
    "    )\n",
    "    \n",
    "    # Providers that support streaming (all three providers support stream=True)\n",
    "    streaming_providers = [\"openai:whisper-1\", \"deepgram:nova-2\", \"google:latest_long\"]\n",
    "    \n",
    "    for model in streaming_providers:\n",
    "        try:\n",
    "            print(f\"\\n--- Streaming with {model} ---\")\n",
    "            result = client.audio.transcriptions.create(\n",
    "                model=model,\n",
    "                file=audio_file,\n",
    "                options=streaming_options  # stream=True is set in options\n",
    "            )\n",
    "            \n",
    "            # Handle streaming vs non-streaming results\n",
    "            if isinstance(result, TranscriptionResult):\n",
    "                # Got batch result instead of streaming\n",
    "                print(f\"Got batch result: {result.text[:50]}...\")\n",
    "            else:\n",
    "                # Should be streaming response\n",
    "                print(\"Processing streaming chunks...\")\n",
    "                chunk_count = 0\n",
    "                try:\n",
    "                    async for chunk in result:\n",
    "                        chunk_count += 1\n",
    "                        print(f\"Chunk {chunk_count}: {'[FINAL]' if chunk.is_final else '[INTERIM]'} {chunk.text}\")\n",
    "                        if chunk_count >= 3:  # Limit output for demo\n",
    "                            break\n",
    "                except Exception as stream_error:\n",
    "                    print(f\"Streaming processing error: {stream_error}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {model}: {e}\")\n",
    "\n",
    "# Run streaming example\n",
    "print(\"Running streaming example...\")\n",
    "try:\n",
    "    import asyncio\n",
    "    asyncio.create_task(streaming_example())\n",
    "    print(\"Streaming task created (may run in background)\")\n",
    "except Exception as e:\n",
    "    print(f\"Streaming example error: {e}\")\n",
    "    print(\"Note: Streaming may not work in all environments or without proper audio files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Detailed timestamps with TranscriptionOptions\n",
    "print(\"\\n=== Detailed Timestamps Example ===\")\n",
    "\n",
    "timestamp_options = TranscriptionOptions(\n",
    "    language=\"en\",\n",
    "    include_word_timestamps=True,\n",
    "    include_segment_timestamps=True,\n",
    "    custom_parameters={\n",
    "        \"openai\": {\n",
    "            \"response_format\": \"verbose_json\",\n",
    "            \"timestamp_granularities\": [\"word\", \"segment\"]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = client.audio.transcriptions.create(\n",
    "        model=\"openai:whisper-1\",\n",
    "        file=audio_file,\n",
    "        options=timestamp_options\n",
    "    )\n",
    "    if isinstance(result, TranscriptionResult):\n",
    "        print(f\"Text: {result.text}\")\n",
    "        if result.words:\n",
    "            print(f\"Words: {len(result.words)}\")\n",
    "            for word in result.words[:3]:\n",
    "                print(f\"  {word.word}: {word.start:.1f}s-{word.end:.1f}s\")\n",
    "        if result.segments:\n",
    "            print(f\"Segments: {len(result.segments)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Timestamp example error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed3f0f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the new unified ASR interface with:\n",
    "\n",
    "1. **TranscriptionOptions**: Unified configuration that works across all providers\n",
    "2. **Provider-specific features**: Access unique features via `custom_parameters`\n",
    "3. **Streaming support**: Real-time transcription where supported\n",
    "\n",
    "### Environment Setup Required:\n",
    "\n",
    "- **OpenAI**: `OPENAI_API_KEY`\n",
    "- **Deepgram**: `DEEPGRAM_API_KEY`  \n",
    "- **Google**: `GOOGLE_PROJECT_ID`, `GOOGLE_REGION`, `GOOGLE_APPLICATION_CREDENTIALS`\n",
    "\n",
    "### Key Benefits:\n",
    "\n",
    "- Write once, run on any provider\n",
    "- Access provider-specific features when needed\n",
    "- Consistent error handling and response format\n",
    "- Easy provider switching for testing and optimization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
